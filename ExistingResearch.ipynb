{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUHx6zexuQ1MAwhbJ1Rmwq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jw0bKgnXr5tq"
      },
      "outputs": [],
      "source": [
        "#Here we attempt to replicate research findings from Persio and Honchar from \"Artificial Neural Networks Approach to the Forecast of Stock Market Price Movements\" (2016)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "import os\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Ingestion\n",
        "look_back = 30\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "#Replicate paper's data: ~ 16k data points from S&P 500 index\n",
        "stock_data = yf.download('^GSPC', start='1950-01-01', end='2016-12-31')\n",
        "stock_data.columns = stock_data.columns.droplevel(1)\n",
        "stock_data.columns.name = None\n",
        "\n",
        "prices = stock_data\n",
        "prices['Date'] = prices.index\n",
        "prices = prices.dropna()\n",
        "\n",
        "#Cast numeric data to type float\n",
        "prices[['Open', 'High', 'Low', 'Close']] = prices[['Open', 'High', 'Low', 'Close']].astype(float)\n",
        "prices['Volume'] = prices['Volume'].astype(int)\n",
        "\n",
        "#Create percentage change column for each col to normalize data.\n",
        "prices[['Open_pc', 'High_pc', 'Low_pc', 'Close_pc', 'Volume_pc']] = prices[['Open', 'High', 'Low', 'Close', 'Volume']].pct_change()\n",
        "\n",
        "#Take the previous 30 days of price data (only for close for this paper)\n",
        "for num in range(0,look_back):\n",
        "  col_name = 'Close_pc' + '_' + str(num)\n",
        "  prices[col_name] = prices['Close_pc'].shift(num+1)\n",
        "\n",
        "\n",
        "#Keep cols on date, movement class, previous -lookback period- days\n",
        "cols_to_keep = []\n",
        "cols_to_keep = ['Date'] + [col for col in prices.columns if 'Close_pc' in col]\n",
        "prices_pattern = prices[cols_to_keep]\n",
        "all_data = pd.concat([all_data, prices_pattern], ignore_index=True)\n",
        "\n",
        "all_data = all_data.dropna()\n",
        "all_data['Movement_Class'] = np.where(all_data['Close_pc']>0, 'Positive', 'Negative')\n",
        "print(len(all_data))\n",
        "print(all_data.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJR7lujXCW1X",
        "outputId": "b76863c4-88dd-4a47-deec-41b350df26f9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2622371228.py:6: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  stock_data = yf.download('^GSPC', start='1950-01-01', end='2016-12-31')\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16828\n",
            "         Date  Close_pc  Close_pc_0  Close_pc_1  Close_pc_2  Close_pc_3  \\\n",
            "31 1950-02-16 -0.004103    0.000000   -0.010441   -0.002315    0.004067   \n",
            "32 1950-02-17  0.009417   -0.004103    0.000000   -0.010441   -0.002315   \n",
            "33 1950-02-20  0.002916    0.009417   -0.004103    0.000000   -0.010441   \n",
            "34 1950-02-21 -0.001744    0.002916    0.009417   -0.004103    0.000000   \n",
            "35 1950-02-23  0.002330   -0.001744    0.002916    0.009417   -0.004103   \n",
            "36 1950-02-24  0.004067    0.002330   -0.001744    0.002916    0.009417   \n",
            "37 1950-02-27  0.000000    0.004067    0.002330   -0.001744    0.002916   \n",
            "38 1950-02-28 -0.003472    0.000000    0.004067    0.002330   -0.001744   \n",
            "39 1950-03-01  0.001161   -0.003472    0.000000    0.004067    0.002330   \n",
            "40 1950-03-02 -0.000580    0.001161   -0.003472    0.000000    0.004067   \n",
            "\n",
            "    Close_pc_4  Close_pc_5  Close_pc_6  Close_pc_7  Close_pc_8  Close_pc_9  \\\n",
            "31   -0.001161   -0.005196    0.001735    0.003482    0.010557    0.000000   \n",
            "32    0.004067   -0.001161   -0.005196    0.001735    0.003482    0.010557   \n",
            "33   -0.002315    0.004067   -0.001161   -0.005196    0.001735    0.003482   \n",
            "34   -0.010441   -0.002315    0.004067   -0.001161   -0.005196    0.001735   \n",
            "35    0.000000   -0.010441   -0.002315    0.004067   -0.001161   -0.005196   \n",
            "36   -0.004103    0.000000   -0.010441   -0.002315    0.004067   -0.001161   \n",
            "37    0.009417   -0.004103    0.000000   -0.010441   -0.002315    0.004067   \n",
            "38    0.002916    0.009417   -0.004103    0.000000   -0.010441   -0.002315   \n",
            "39   -0.001744    0.002916    0.009417   -0.004103    0.000000   -0.010441   \n",
            "40    0.002330   -0.001744    0.002916    0.009417   -0.004103    0.000000   \n",
            "\n",
            "    Close_pc_10  Close_pc_11  Close_pc_12  Close_pc_13  Close_pc_14  \\\n",
            "31     0.001763     0.011891     0.005380    -0.000597    -0.007117   \n",
            "32     0.000000     0.001763     0.011891     0.005380    -0.000597   \n",
            "33     0.010557     0.000000     0.001763     0.011891     0.005380   \n",
            "34     0.003482     0.010557     0.000000     0.001763     0.011891   \n",
            "35     0.001735     0.003482     0.010557     0.000000     0.001763   \n",
            "36    -0.005196     0.001735     0.003482     0.010557     0.000000   \n",
            "37    -0.001161    -0.005196     0.001735     0.003482     0.010557   \n",
            "38     0.004067    -0.001161    -0.005196     0.001735     0.003482   \n",
            "39    -0.002315     0.004067    -0.001161    -0.005196     0.001735   \n",
            "40    -0.010441    -0.002315     0.004067    -0.001161    -0.005196   \n",
            "\n",
            "    Close_pc_15  Close_pc_16  Close_pc_17  Close_pc_18  Close_pc_19  \\\n",
            "31    -0.003546     0.001183     0.001778     0.001187    -0.000593   \n",
            "32    -0.007117    -0.003546     0.001183     0.001778     0.001187   \n",
            "33    -0.000597    -0.007117    -0.003546     0.001183     0.001778   \n",
            "34     0.005380    -0.000597    -0.007117    -0.003546     0.001183   \n",
            "35     0.011891     0.005380    -0.000597    -0.007117    -0.003546   \n",
            "36     0.001763     0.011891     0.005380    -0.000597    -0.007117   \n",
            "37     0.000000     0.001763     0.011891     0.005380    -0.000597   \n",
            "38     0.010557     0.000000     0.001763     0.011891     0.005380   \n",
            "39     0.003482     0.010557     0.000000     0.001763     0.011891   \n",
            "40     0.001735     0.003482     0.010557     0.000000     0.001763   \n",
            "\n",
            "    Close_pc_20  Close_pc_21  Close_pc_22  Close_pc_23  Close_pc_24  \\\n",
            "31     0.008373     0.002999    -0.005370    -0.019310     0.003523   \n",
            "32    -0.000593     0.008373     0.002999    -0.005370    -0.019310   \n",
            "33     0.001187    -0.000593     0.008373     0.002999    -0.005370   \n",
            "34     0.001778     0.001187    -0.000593     0.008373     0.002999   \n",
            "35     0.001183     0.001778     0.001187    -0.000593     0.008373   \n",
            "36    -0.003546     0.001183     0.001778     0.001187    -0.000593   \n",
            "37    -0.007117    -0.003546     0.001183     0.001778     0.001187   \n",
            "38    -0.000597    -0.007117    -0.003546     0.001183     0.001778   \n",
            "39     0.005380    -0.000597    -0.007117    -0.003546     0.001183   \n",
            "40     0.011891     0.005380    -0.000597    -0.007117    -0.003546   \n",
            "\n",
            "    Close_pc_25  Close_pc_26  Close_pc_27  Close_pc_28  Close_pc_29  \\\n",
            "31    -0.002927     0.005889     0.002953     0.004748     0.011405   \n",
            "32     0.003523    -0.002927     0.005889     0.002953     0.004748   \n",
            "33    -0.019310     0.003523    -0.002927     0.005889     0.002953   \n",
            "34    -0.005370    -0.019310     0.003523    -0.002927     0.005889   \n",
            "35     0.002999    -0.005370    -0.019310     0.003523    -0.002927   \n",
            "36     0.008373     0.002999    -0.005370    -0.019310     0.003523   \n",
            "37    -0.000593     0.008373     0.002999    -0.005370    -0.019310   \n",
            "38     0.001187    -0.000593     0.008373     0.002999    -0.005370   \n",
            "39     0.001778     0.001187    -0.000593     0.008373     0.002999   \n",
            "40     0.001183     0.001778     0.001187    -0.000593     0.008373   \n",
            "\n",
            "   Movement_Class  \n",
            "31       Negative  \n",
            "32       Positive  \n",
            "33       Positive  \n",
            "34       Negative  \n",
            "35       Positive  \n",
            "36       Positive  \n",
            "37       Negative  \n",
            "38       Negative  \n",
            "39       Positive  \n",
            "40       Negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Normalize data - zero mean, unit variance\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(all_data.iloc[:,1:31][::-1])\n",
        "x = features_scaled\n",
        "\n",
        "#Encode label axes\n",
        "y_raw = all_data['Movement_Class'].values\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y_raw)\n",
        "y = to_categorical(y_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=99, stratify=y)\n",
        "#MLP model:2 hidden layers with 500, 250 neurons respectively, with a dropout after first layer\n",
        "model_MLP = Sequential()\n",
        "model_MLP.add(Input(shape=(30,)))\n",
        "\n",
        "model_MLP.add(Dense(500, activation = 'relu' ))\n",
        "model_MLP.add(Dropout(0.5))\n",
        "model_MLP.add(Dense(250, activation = 'relu'))\n",
        "model_MLP.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "model_MLP.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_MLP.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model_MLP.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDuV0hFSEAuu",
        "outputId": "a5b2c3a4-524f-4efb-d598-0b041bf66c0f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5123 - loss: 0.7172\n",
            "Epoch 2/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5339 - loss: 0.6895\n",
            "Epoch 3/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5393 - loss: 0.6866\n",
            "Epoch 4/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5528 - loss: 0.6835\n",
            "Epoch 5/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5677 - loss: 0.6786\n",
            "Epoch 6/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5684 - loss: 0.6758\n",
            "Epoch 7/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5769 - loss: 0.6735\n",
            "Epoch 8/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5833 - loss: 0.6685\n",
            "Epoch 9/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5833 - loss: 0.6649\n",
            "Epoch 10/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 0.6570\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.6994\n",
            "Test Loss: 0.7082214951515198, Test Accuracy: 0.5237670540809631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP eval\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test_true_labels = np.argmax(y_test, axis=1)\n",
        "y_pred = model_MLP.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test_true_labels, y_pred_classes))\n",
        "print(\"0 = Price decrease, 1 = Price increase\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjpoB842SNh7",
        "outputId": "7fc24dd4-6579-404a-de12-d6b3c0704d7b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.41      0.45      1586\n",
            "           1       0.54      0.62      0.58      1780\n",
            "\n",
            "    accuracy                           0.52      3366\n",
            "   macro avg       0.52      0.52      0.51      3366\n",
            "weighted avg       0.52      0.52      0.52      3366\n",
            "\n",
            "0 = Price decrease, 1 = Price increase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "#CNN Model:\n",
        "model_CNN = Sequential()\n",
        "model_CNN.add(Input(shape=(30,1)))\n",
        "# 1st conv layer\n",
        "model_CNN.add(Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
        "model_CNN.add(MaxPooling1D(pool_size=2))\n",
        "# Second Conv Layer\n",
        "model_CNN.add(Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
        "model_CNN.add(MaxPooling1D(pool_size=2))\n",
        "model_CNN.add(Dropout(0.1))\n",
        "#MLP layer - 2 layers with dropout after the first\n",
        "model_CNN.add(Flatten())\n",
        "model_CNN.add(Dense(100, activation='relu'))\n",
        "model_CNN.add(Dropout(0.3))\n",
        "model_CNN.add(Dense(50, activation='relu'))\n",
        "model_CNN.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model_CNN.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_CNN.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "loss_cnn, acc_cnn = model_CNN.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss_cnn:.4f}, Test Accuracy: {acc_cnn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdIo_ooUrHBi",
        "outputId": "06e1723f-d6eb-46dc-c71c-14e1acc64643"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5042 - loss: 0.6955\n",
            "Epoch 2/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5267 - loss: 0.6922\n",
            "Epoch 3/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5294 - loss: 0.6915\n",
            "Epoch 4/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 0.6913\n",
            "Epoch 5/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5269 - loss: 0.6910\n",
            "Epoch 6/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5261 - loss: 0.6912\n",
            "Epoch 7/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5305 - loss: 0.6900\n",
            "Epoch 8/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 0.6893\n",
            "Epoch 9/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5477 - loss: 0.6863\n",
            "Epoch 10/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5432 - loss: 0.6855\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5263 - loss: 0.6913\n",
            "Test Loss: 0.6919, Test Accuracy: 0.5255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN eval\n",
        "y_pred_CNN = model_CNN.predict(X_test)\n",
        "y_pred_classes_CNN = y_pred_CNN.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test_true_labels, y_pred_classes_CNN))\n",
        "print(\"0 = Price decrease, 1 = Price increase\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0LswL8s3iga",
        "outputId": "0bb92620-a32f-484a-85d2-64626a83efb2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.04      0.08      1586\n",
            "           1       0.53      0.95      0.68      1780\n",
            "\n",
            "    accuracy                           0.52      3366\n",
            "   macro avg       0.48      0.50      0.38      3366\n",
            "weighted avg       0.48      0.52      0.39      3366\n",
            "\n",
            "0 = Price decrease, 1 = Price increase\n"
          ]
        }
      ]
    }
  ]
}